# About this Repository
This repository will contain the base toolchain and demo for Ubicoustics (presented at UIST 2018). Here you'll find code to run a real-time demo. Featurized numpy arrays are forthcoming. Stay tuned!

# Overview
The repo currently contains two main folders: `/backend` which contains code that runs live prediction using your local microphone, and `/dl-pipeline` which contains toolchain code for training and testing models. The rest of this documentation outlines everything you need to run the basic system.

# Reference
Citation reference (below). Download PDF here.
`Gierad Laput, Karan Ahuja, Mayank Goel, Chris Harrison. 2018. Ubicoustics: Plug-and-Play Acoustic Activity Recognition. In Proceedings of the 31st Annual Symposium on User Interface Software and Technology (UIST '18). ACM, New York, NY, USA.`

BibTex Reference:
```
@inproceedings {ubicoustics,
  author={Laput, G. and Ahuja, K. and Goel, M. and Harrison, C},
  title={Ubicoustics: Plug-and-Play Acoustic Activity Recognition},
  booktitle={Proceedings of the 31st Annual Symposium on User Interface Software and Technology},
  series={USIT '18},
  year={2018},
  location={Berlin, Germany},
  numpages={10},
  publisher={ACM},
  address={New York, NY, USA}
}
```

# License
Ubicoustics is freely available for free non-commercial use, and may be redistributed under these conditions. Please see the license for further details. For a commercial license, please contact Gierad Laput and Chris Harrison.
